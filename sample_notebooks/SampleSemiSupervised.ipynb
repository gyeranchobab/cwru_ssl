{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample of Semi-supervised Learning Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_X = torch.rand(8, 1, 32)\n",
    "SAMPLE_Y = torch.randint(2, [8])\n",
    "EPOCH = 20\n",
    "MASK = torch.tensor([True, True, False, False, False, False, False, False])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CuteModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CuteModel, self).__init__()\n",
    "        self.enc_layer1 = nn.Conv1d(1, 8, kernel_size=5, stride=2)\n",
    "        self.enc_layer2 = nn.Conv1d(8, 8, kernel_size=5, stride=2)\n",
    "        \n",
    "        self.decoder = nn.Linear(8, 6)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.enc_layer1(x)\n",
    "        x = self.enc_layer2(x)\n",
    "        \n",
    "        x = x.mean(dim=-1)\n",
    "        \n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Pseudo-Labeling\n",
    "either on probability or cross entropy\n",
    "temporary vs permanently\n",
    "threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([False, False, False, False, False, False, False, False])\n",
      "tensor([False, False, False, False, False, False, False, False])\n",
      "tensor([False, False, False, False, False, False, False, False])\n",
      "tensor([False, False, False, False, False, False, False, False])\n",
      "tensor([False, False, False, False, False, False, False, False])\n",
      "tensor([False, False, False, False, False, False, False, False])\n",
      "tensor([False, False, False, False, False, False, False, False])\n",
      "tensor([False, False, False, False, False, False, False, False])\n",
      "tensor([False, False, False, False, False, False, False, False])\n",
      "tensor([False, False, False, False, False, False, False, False])\n",
      "tensor([False, False, False, False, False, False, False, False])\n",
      "tensor([False, False, False, False, False, False, False, False])\n",
      "tensor([False, False, False, False, False, False, False, False])\n",
      "tensor([False, False, False, False, False, False, False, False])\n",
      "tensor([False, False, False, False, False, False, False, False])\n",
      "tensor([False, False, False, False, False, False, False, False])\n",
      "tensor([False, False, False, False, False, False, False, False])\n",
      "tensor([False, False, False, False, False, False, False, False])\n",
      "tensor([False, False, False, False, False, False, False, False])\n",
      "tensor([False, False, False, False, False, False, False, False])\n"
     ]
    }
   ],
   "source": [
    "model = CuteModel()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "THRES = 0.25  # this is very low value for tutorial. You should use higher value(0.7~)\n",
    "\n",
    "for e in range(EPOCH):\n",
    "    p = model(SAMPLE_X)\n",
    "    pred = torch.argmax(p, dim=1)\n",
    "    \n",
    "    prob = F.softmax(p, dim=-1)\n",
    "    PSEUDO = (~MASK) & (prob.max(dim=-1)[0]>THRES)\n",
    "    print(PSEUDO)\n",
    "    p_pseudo = torch.cat([p[MASK], p[PSEUDO]], dim=0)\n",
    "    y_pseudo = torch.cat([SAMPLE_Y[MASK], pred[PSEUDO]], dim=0)\n",
    "    \n",
    "    if PSEUDO.any() or MASK.any():\n",
    "        loss = nn.CrossEntropyLoss()(p_pseudo, y_pseudo)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Entropy Minimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HLoss(x):\n",
    "    b = F.softmax(x, dim=1) * F.log_softmax(x, dim=1)\n",
    "    b = -1.0 * b.mean()\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[total] : 4.67348,\t[CrossEntropy] : 1.72726,\t[Entropy] : 0.29462\n",
      "[total] : 4.65432,\t[CrossEntropy] : 1.70813,\t[Entropy] : 0.29462\n",
      "[total] : 4.63489,\t[CrossEntropy] : 1.68920,\t[Entropy] : 0.29457\n",
      "[total] : 4.61513,\t[CrossEntropy] : 1.67043,\t[Entropy] : 0.29447\n",
      "[total] : 4.59503,\t[CrossEntropy] : 1.65181,\t[Entropy] : 0.29432\n",
      "[total] : 4.57455,\t[CrossEntropy] : 1.63332,\t[Entropy] : 0.29412\n",
      "[total] : 4.55368,\t[CrossEntropy] : 1.61496,\t[Entropy] : 0.29387\n",
      "[total] : 4.53238,\t[CrossEntropy] : 1.59672,\t[Entropy] : 0.29357\n",
      "[total] : 4.51063,\t[CrossEntropy] : 1.57858,\t[Entropy] : 0.29321\n",
      "[total] : 4.48840,\t[CrossEntropy] : 1.56052,\t[Entropy] : 0.29279\n",
      "[total] : 4.46565,\t[CrossEntropy] : 1.54253,\t[Entropy] : 0.29231\n",
      "[total] : 4.44235,\t[CrossEntropy] : 1.52460,\t[Entropy] : 0.29178\n",
      "[total] : 4.41847,\t[CrossEntropy] : 1.50671,\t[Entropy] : 0.29118\n",
      "[total] : 4.39398,\t[CrossEntropy] : 1.48886,\t[Entropy] : 0.29051\n",
      "[total] : 4.36884,\t[CrossEntropy] : 1.47103,\t[Entropy] : 0.28978\n",
      "[total] : 4.34302,\t[CrossEntropy] : 1.45321,\t[Entropy] : 0.28898\n",
      "[total] : 4.31648,\t[CrossEntropy] : 1.43539,\t[Entropy] : 0.28811\n",
      "[total] : 4.28918,\t[CrossEntropy] : 1.41755,\t[Entropy] : 0.28716\n",
      "[total] : 4.26107,\t[CrossEntropy] : 1.39968,\t[Entropy] : 0.28614\n",
      "[total] : 4.23213,\t[CrossEntropy] : 1.38178,\t[Entropy] : 0.28503\n"
     ]
    }
   ],
   "source": [
    "model = CuteModel()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "BETA = 10\n",
    "\n",
    "for e in range(EPOCH):\n",
    "    p = model(SAMPLE_X)\n",
    "    pred = torch.argmax(p, dim=1)\n",
    "    \n",
    "    class_loss = nn.CrossEntropyLoss()(p[MASK], SAMPLE_Y[MASK])\n",
    "    entropy_loss = HLoss(p[~MASK])\n",
    "    \n",
    "    loss = class_loss + BETA*entropy_loss\n",
    "    print('[total] : %.5f,\\t[CrossEntropy] : %.5f,\\t[Entropy] : %.5f'%(loss.item(), class_loss.item(), entropy_loss.item()))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Consistency Regularization\n",
    "you can give perturbation by temporal shift, adding noise, adversarial training, etc.\n",
    "It is important that the perturbation should be realistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CrossEntropy(p,q):\n",
    "    b = F.softmax(p, dim=1) * F.log_softmax(q, dim=1)\n",
    "    b = -1.0*b.mean()\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[total] : 148.50153,\t[CrossEntropy] : 1.85081,\t[Distance] : 0.29330\n",
      "[total] : 148.05801,\t[CrossEntropy] : 1.85874,\t[Distance] : 0.29240\n",
      "[total] : 147.73544,\t[CrossEntropy] : 1.86700,\t[Distance] : 0.29174\n",
      "[total] : 147.70023,\t[CrossEntropy] : 1.87560,\t[Distance] : 0.29165\n",
      "[total] : 147.12126,\t[CrossEntropy] : 1.88451,\t[Distance] : 0.29047\n",
      "[total] : 146.94798,\t[CrossEntropy] : 1.89376,\t[Distance] : 0.29011\n",
      "[total] : 146.59541,\t[CrossEntropy] : 1.90337,\t[Distance] : 0.28938\n",
      "[total] : 146.06557,\t[CrossEntropy] : 1.91335,\t[Distance] : 0.28830\n",
      "[total] : 145.96964,\t[CrossEntropy] : 1.92371,\t[Distance] : 0.28809\n",
      "[total] : 145.51291,\t[CrossEntropy] : 1.93444,\t[Distance] : 0.28716\n",
      "[total] : 145.00038,\t[CrossEntropy] : 1.94561,\t[Distance] : 0.28611\n",
      "[total] : 144.36263,\t[CrossEntropy] : 1.95722,\t[Distance] : 0.28481\n",
      "[total] : 143.80521,\t[CrossEntropy] : 1.96933,\t[Distance] : 0.28367\n",
      "[total] : 143.37509,\t[CrossEntropy] : 1.98197,\t[Distance] : 0.28279\n",
      "[total] : 142.92053,\t[CrossEntropy] : 1.99519,\t[Distance] : 0.28185\n",
      "[total] : 142.25037,\t[CrossEntropy] : 2.00905,\t[Distance] : 0.28048\n",
      "[total] : 141.85118,\t[CrossEntropy] : 2.02358,\t[Distance] : 0.27966\n",
      "[total] : 140.93353,\t[CrossEntropy] : 2.03879,\t[Distance] : 0.27779\n",
      "[total] : 140.47437,\t[CrossEntropy] : 2.05480,\t[Distance] : 0.27684\n",
      "[total] : 139.52196,\t[CrossEntropy] : 2.07169,\t[Distance] : 0.27490\n"
     ]
    }
   ],
   "source": [
    "model = CuteModel()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "BETA = 500\n",
    "\n",
    "for e in range(EPOCH):\n",
    "    pp = torch.randint(1,16,[1])\n",
    "    X_original = SAMPLE_X[:,:,:16]        # here only used the half of the input\n",
    "    X_perturbed = SAMPLE_X[:,:,pp:pp+16]  # perturbation : shifting\n",
    "    \n",
    "    p_original = model(X_original)\n",
    "    p_perturbed = model(X_perturbed)\n",
    "    \n",
    "    class_loss = nn.CrossEntropyLoss()(p_original[MASK], SAMPLE_Y[MASK])\n",
    "    dist_loss = CrossEntropy(p_original, p_perturbed)\n",
    "    \n",
    "    loss = class_loss + BETA*dist_loss\n",
    "    print('[total] : %.5f,\\t[CrossEntropy] : %.5f,\\t[Distance] : %.5f'%(loss.item(), class_loss.item(), dist_loss.item()))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
