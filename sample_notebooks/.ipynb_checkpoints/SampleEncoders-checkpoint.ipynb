{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Various Encoder Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_X = torch.rand(2, 1, 32)\n",
    "SAMPLE_Y = torch.randint(2, [2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Cute Model\n",
    "    : cute version of our SimpleModel in Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CuteModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CuteModel, self).__init__()\n",
    "        self.enc_layer1 = nn.Conv1d(1, 8, kernel_size=5, stride=2)\n",
    "        self.enc_layer2 = nn.Conv1d(8, 8, kernel_size=5, stride=2)\n",
    "        \n",
    "        self.decoder = nn.Linear(8, 6)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        print('Input size :\\t\\t',x.size())\n",
    "        \n",
    "        x = self.enc_layer1(x)\n",
    "        print('After 1st layer :\\t',x.size())\n",
    "        x = self.enc_layer2(x)\n",
    "        print('After 2nd layer :\\t',x.size())\n",
    "        \n",
    "        x = x.mean(dim=-1)\n",
    "        print('After mean pool :\\t',x.size())\n",
    "        \n",
    "        x = self.decoder(x)\n",
    "        print('After decoder :\\t\\t',x.size())\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input size :\t\t torch.Size([2, 1, 32])\n",
      "After 1st layer :\t torch.Size([2, 8, 14])\n",
      "After 2nd layer :\t torch.Size([2, 8, 5])\n",
      "After mean pool :\t torch.Size([2, 8])\n",
      "After decoder :\t\t torch.Size([2, 6])\n",
      "[loss] :  tensor(1.8711, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "model = CuteModel()\n",
    "p = model(SAMPLE_X)\n",
    "loss = nn.CrossEntropyLoss()(p, SAMPLE_Y)\n",
    "print('[loss] : ', loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. DilatedCNN\n",
    "- In definition of each *self.enc_layer#*, you can define dilation of the Conv1d layer.\n",
    "\n",
    "<pre>\n",
    "self.enc_layer1 = nn.Conv1d(1, 8, kernel_size=5, stride=3, <b>dilation=2</b>)\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DilatedCNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DilatedCNNModel, self).__init__()\n",
    "        self.enc_layer1 = nn.Conv1d(1, 8, kernel_size=5, stride=2, dilation=2)\n",
    "        self.enc_layer2 = nn.Conv1d(8, 8, kernel_size=5, stride=2, dilation=2)\n",
    "        \n",
    "        self.decoder = nn.Linear(8, 6)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        print('Input size :\\t\\t',x.size())\n",
    "\n",
    "        x = self.enc_layer1(x)\n",
    "        print('After 1st layer :\\t',x.size())\n",
    "        x = self.enc_layer2(x)\n",
    "        print('After 2nd layer :\\t',x.size())\n",
    "        \n",
    "        x = x.mean(dim=-1)\n",
    "        print('After mean pool :\\t',x.size())\n",
    "        \n",
    "        x = self.decoder(x)\n",
    "        print('After decoder :\\t\\t',x.size())\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input size :\t\t torch.Size([2, 1, 32])\n",
      "After 1st layer :\t torch.Size([2, 8, 12])\n",
      "After 2nd layer :\t torch.Size([2, 8, 2])\n",
      "After mean pool :\t torch.Size([2, 8])\n",
      "After decoder :\t\t torch.Size([2, 6])\n",
      "[loss] :  tensor(1.6990, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "model = DilatedCNNModel()\n",
    "p = model(SAMPLE_X)\n",
    "loss = nn.CrossEntropyLoss()(p, SAMPLE_Y)\n",
    "print('[loss] : ', loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Cumulate each layer outputs\n",
    "- You can easily concatenate outputs of each encoding layers.\n",
    "\n",
    "<pre>\n",
    "x = torch.cat([x1,x2], dim=-1)\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CumulateModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CumulateModel, self).__init__()\n",
    "        self.enc_layer1 = nn.Conv1d(1, 8, kernel_size=5, stride=3)\n",
    "        self.enc_layer2 = nn.Conv1d(8, 8, kernel_size=5, stride=3)\n",
    "        \n",
    "        self.decoder = nn.Linear(2*8, 6)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        print('Input size :\\t\\t',x.size())\n",
    "\n",
    "        x1 = self.enc_layer1(x)\n",
    "        print('After 1st layer :\\t',x1.size())\n",
    "        x2 = self.enc_layer2(x1)\n",
    "        print('After 2nd layer :\\t',x2.size())\n",
    "        \n",
    "        x1 = x1.mean(dim=-1)\n",
    "        print('After pool x1 :\\t\\t',x1.size())\n",
    "        x2 = x2.mean(dim=-1)\n",
    "        print('After pool x2 :\\t\\t',x2.size())\n",
    "        \n",
    "        x = torch.cat([x1,x2], dim=-1)\n",
    "        print('After concat :\\t\\t', x.size())\n",
    "        \n",
    "        x = self.decoder(x)\n",
    "        print('After decoder :\\t\\t',x2.size())\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input size :\t\t torch.Size([2, 1, 32])\n",
      "After 1st layer :\t torch.Size([2, 8, 10])\n",
      "After 2nd layer :\t torch.Size([2, 8, 2])\n",
      "After pool x1 :\t\t torch.Size([2, 8])\n",
      "After pool x2 :\t\t torch.Size([2, 8])\n",
      "After concat :\t\t torch.Size([2, 16])\n",
      "After decoder :\t\t torch.Size([2, 8])\n",
      "[loss] :  tensor(1.9182, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "model = CumulateModel()\n",
    "p = model(SAMPLE_X)\n",
    "loss = nn.CrossEntropyLoss()(p, SAMPLE_Y)\n",
    "print('[loss] : ', loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Variational Model\n",
    "- You can compute **mean** and **log variance** of *z*.\n",
    "<pre>\n",
    "z_mu = self.enc_mu(x)\n",
    "z_logvar = self.enc_logvar(x)\n",
    "</pre>\n",
    "\n",
    "- From *z_mu* and *z_logvar*, you can sample *z*, with **reparameterization trick**.\n",
    "<pre>\n",
    "z = self._reparam(z_mu, z_logvar)\n",
    "</pre>\n",
    "\n",
    "- You should compute **KL-Divergence** to map latent distriution to prior distribution.\n",
    "<pre>\n",
    "self.kld = self._kld_gauss(z_mu, z_logvar)\n",
    "</pre>\n",
    "\n",
    "- We provide you sample functions for **reparameterization trick** and computing **KL-Divergence**, so don't worry and just copy them!\n",
    "<pre>\n",
    "def _reparam(self, mu, logvar):\n",
    "def _kld_gauss(self, mu, logvar):\n",
    "</pre>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariationalModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VariationalModel, self).__init__()\n",
    "        self.enc_layer1 = nn.Conv1d(1, 8, kernel_size=5, stride=3)\n",
    "        self.enc_layer2 = nn.Conv1d(8, 8, kernel_size=5, stride=3)\n",
    "        \n",
    "        self.enc_mu = nn.Linear(8, 8)\n",
    "        self.enc_logvar = nn.Linear(8, 8)\n",
    "        \n",
    "        self.kld = torch.tensor(0)\n",
    "        \n",
    "        self.decoder = nn.Linear(8, 6)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        print('Input size :\\t\\t',x.size())\n",
    "        \n",
    "        x = self.enc_layer1(x)\n",
    "        print('After 1st layer :\\t',x.size())\n",
    "        x = self.enc_layer2(x)\n",
    "        print('After 2nd layer :\\t',x.size())\n",
    "        \n",
    "        x = x.mean(dim=-1)\n",
    "        print('After mean pool :\\t',x.size())\n",
    "        \n",
    "        z_mu = self.enc_mu(x)\n",
    "        z_logvar = self.enc_logvar(x)\n",
    "        print('z_mu & z_logvar :\\t',z_mu.size())\n",
    "        z = self._reparam(z_mu, z_logvar)\n",
    "        print('Sampled z shape :\\t',z.size())\n",
    "        \n",
    "        self.kld = self._kld_gauss(z_mu, z_logvar)\n",
    "        \n",
    "        x = self.decoder(z)\n",
    "        print('After decoder :\\t\\t',x.size())\n",
    "        return x\n",
    "    \n",
    "    def _reparam(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std = logvar.mul(0.5).exp_()\n",
    "            eps = torch.autograd.Variable(std.data.new(std.size()).normal_())\n",
    "            return eps.mul(std).add_(mu)\n",
    "        else:\n",
    "            return mu\n",
    "        \n",
    "    def _kld_gauss(self, mu, logvar):\n",
    "        kld_element = -logvar + torch.exp(logvar) + mu**2 - 1\n",
    "        return 0.5 * torch.mean(kld_element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***(IMPORTANT!!!)*** If you want to use variational model and regularize the latent distribution, you should add ***KL-Divergence term*** to the loss term.\n",
    "\n",
    "<pre>\n",
    "...\n",
    "class_loss = CrossEntropyLoss()(pred, target)\n",
    "<b>kld_loss = model.kld</b>\n",
    "total_loss = class_loss + <b>BETA*kld_loss</b>\n",
    "total_loss.backward()\n",
    "...\n",
    "</pre>\n",
    "\n",
    "Also, you can control portion of classification loss and KLD loss by setting BETA. (ex: BETA=0.1 or BETA=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input size :\t\t torch.Size([2, 1, 32])\n",
      "After 1st layer :\t torch.Size([2, 8, 10])\n",
      "After 2nd layer :\t torch.Size([2, 8, 2])\n",
      "After mean pool :\t torch.Size([2, 8])\n",
      "z_mu & z_logvar :\t torch.Size([2, 8])\n",
      "Sampled z shape :\t torch.Size([2, 8])\n",
      "After decoder :\t\t torch.Size([2, 6])\n",
      "[loss] :  tensor(1.6636, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "BETA = 1\n",
    "model = VariationalModel()\n",
    "p = model(SAMPLE_X)\n",
    "loss = nn.CrossEntropyLoss()(p, SAMPLE_Y) + BETA*model.kld\n",
    "print('[loss] : ', loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try build your own model architecture"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
