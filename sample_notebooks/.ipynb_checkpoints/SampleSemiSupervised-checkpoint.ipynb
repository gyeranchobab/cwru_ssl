{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample of Semi-supervised Learning Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_X = torch.rand(8, 1, 32)\n",
    "SAMPLE_Y = torch.randint(2, [8])\n",
    "EPOCH = 20\n",
    "MASK = torch.tensor([True, True, False, False, False, False, False, False])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CuteModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CuteModel, self).__init__()\n",
    "        self.enc_layer1 = nn.Conv1d(1, 8, kernel_size=5, stride=2)\n",
    "        self.enc_layer2 = nn.Conv1d(8, 8, kernel_size=5, stride=2)\n",
    "        \n",
    "        self.decoder = nn.Linear(8, 6)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.enc_layer1(x)\n",
    "        x = self.enc_layer2(x)\n",
    "        \n",
    "        x = x.mean(dim=-1)\n",
    "        \n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Pseudo-Labeling\n",
    "either on probability or cross entropy\n",
    "temporary vs permanently\n",
    "threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([False, False, False, False, False, False, False, False])\n",
      "tensor([False, False, False, False, False, False, False, False])\n",
      "tensor([False, False, False, False, False, False, False, False])\n",
      "tensor([False, False, False, False, False, False, False, False])\n",
      "tensor([False, False, False, False, False, False, False, False])\n",
      "tensor([False, False, False, False, False, False, False, False])\n",
      "tensor([False, False, False, False, False, False, False, False])\n",
      "tensor([False, False, False, False, False, False, False, False])\n",
      "tensor([False, False, False, False, False, False, False, False])\n",
      "tensor([False, False, False, False, False, False, False, False])\n",
      "tensor([False, False, False, False, False, False, False, False])\n",
      "tensor([False, False, False, False, False, False, False, False])\n",
      "tensor([False, False, False, False, False, False, False, False])\n",
      "tensor([False, False, False, False, False, False, False, False])\n",
      "tensor([False, False, False, False, False, False, False, False])\n",
      "tensor([False, False, False, False, False, False, False, False])\n",
      "tensor([False, False, False, False, False, False, False, False])\n",
      "tensor([False, False, False, False, False, False, False, False])\n",
      "tensor([False, False, False, False, False, False, False, False])\n",
      "tensor([False, False, False, False, False, False, False, False])\n"
     ]
    }
   ],
   "source": [
    "model = CuteModel()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "THRES = 0.25  # this is very low value for tutorial. You should use higher value(0.7~)\n",
    "\n",
    "for e in range(EPOCH):\n",
    "    p = model(SAMPLE_X)\n",
    "    pred = torch.argmax(p, dim=1)\n",
    "    \n",
    "    prob = F.softmax(p, dim=-1)\n",
    "    PSEUDO = (~MASK) & (prob.max(dim=-1)[0]>THRES)\n",
    "    print(PSEUDO)\n",
    "    p_pseudo = torch.cat([p[MASK], p[PSEUDO]], dim=0)\n",
    "    y_pseudo = torch.cat([SAMPLE_Y[MASK], pred[PSEUDO]], dim=0)\n",
    "    \n",
    "    if PSEUDO.any() or M.any():\n",
    "        loss = nn.CrossEntropyLoss()(p_pseudo, y_pseudo)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Entropy Minimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HLoss(x):\n",
    "    b = F.softmax(x, dim=1) * F.log_softmax(x, dim=1)\n",
    "    b = -1.0 * b.mean()\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[total] : 4.88817,\t[CrossEntropy] : 1.97144,\t[Entropy] : 0.29167\n",
      "[total] : 4.87417,\t[CrossEntropy] : 1.95788,\t[Entropy] : 0.29163\n",
      "[total] : 4.86012,\t[CrossEntropy] : 1.94452,\t[Entropy] : 0.29156\n",
      "[total] : 4.84598,\t[CrossEntropy] : 1.93134,\t[Entropy] : 0.29146\n",
      "[total] : 4.83171,\t[CrossEntropy] : 1.91829,\t[Entropy] : 0.29134\n",
      "[total] : 4.81731,\t[CrossEntropy] : 1.90534,\t[Entropy] : 0.29120\n",
      "[total] : 4.80271,\t[CrossEntropy] : 1.89246,\t[Entropy] : 0.29103\n",
      "[total] : 4.78790,\t[CrossEntropy] : 1.87960,\t[Entropy] : 0.29083\n",
      "[total] : 4.77283,\t[CrossEntropy] : 1.86675,\t[Entropy] : 0.29061\n",
      "[total] : 4.75747,\t[CrossEntropy] : 1.85386,\t[Entropy] : 0.29036\n",
      "[total] : 4.74179,\t[CrossEntropy] : 1.84092,\t[Entropy] : 0.29009\n",
      "[total] : 4.72577,\t[CrossEntropy] : 1.82791,\t[Entropy] : 0.28979\n",
      "[total] : 4.70935,\t[CrossEntropy] : 1.81479,\t[Entropy] : 0.28946\n",
      "[total] : 4.69252,\t[CrossEntropy] : 1.80156,\t[Entropy] : 0.28910\n",
      "[total] : 4.67524,\t[CrossEntropy] : 1.78817,\t[Entropy] : 0.28871\n",
      "[total] : 4.65748,\t[CrossEntropy] : 1.77463,\t[Entropy] : 0.28828\n",
      "[total] : 4.63920,\t[CrossEntropy] : 1.76090,\t[Entropy] : 0.28783\n",
      "[total] : 4.62039,\t[CrossEntropy] : 1.74697,\t[Entropy] : 0.28734\n",
      "[total] : 4.60100,\t[CrossEntropy] : 1.73281,\t[Entropy] : 0.28682\n",
      "[total] : 4.58100,\t[CrossEntropy] : 1.71843,\t[Entropy] : 0.28626\n"
     ]
    }
   ],
   "source": [
    "model = CuteModel()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "BETA = 10\n",
    "\n",
    "for e in range(EPOCH):\n",
    "    p = model(SAMPLE_X)\n",
    "    pred = torch.argmax(p, dim=1)\n",
    "    \n",
    "    class_loss = nn.CrossEntropyLoss()(p[MASK], SAMPLE_Y[MASK])\n",
    "    entropy_loss = HLoss(p[~MASK])\n",
    "    \n",
    "    loss = class_loss + BETA*entropy_loss\n",
    "    print('[total] : %.5f,\\t[CrossEntropy] : %.5f,\\t[Entropy] : %.5f'%(loss.item(), class_loss.item(), entropy_loss.item()))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Consistency Regularization\n",
    "you can give perturbation by temporal shift, adding noise, adversarial training, etc.\n",
    "It is important that the perturbation should be realistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[total] : 6.10509,\t[CrossEntropy] : 1.60278,\t[Distance] : 0.00900\n",
      "[total] : 5.05081,\t[CrossEntropy] : 1.60062,\t[Distance] : 0.00690\n",
      "[total] : 5.79912,\t[CrossEntropy] : 1.59822,\t[Distance] : 0.00840\n",
      "[total] : 4.26081,\t[CrossEntropy] : 1.59619,\t[Distance] : 0.00533\n",
      "[total] : 3.30770,\t[CrossEntropy] : 1.59389,\t[Distance] : 0.00343\n",
      "[total] : 3.77460,\t[CrossEntropy] : 1.59199,\t[Distance] : 0.00437\n",
      "[total] : 6.87218,\t[CrossEntropy] : 1.59002,\t[Distance] : 0.01056\n",
      "[total] : 5.72307,\t[CrossEntropy] : 1.58821,\t[Distance] : 0.00827\n",
      "[total] : 4.98811,\t[CrossEntropy] : 1.58618,\t[Distance] : 0.00680\n",
      "[total] : 3.13149,\t[CrossEntropy] : 1.58424,\t[Distance] : 0.00309\n",
      "[total] : 4.53216,\t[CrossEntropy] : 1.58231,\t[Distance] : 0.00590\n",
      "[total] : 4.53355,\t[CrossEntropy] : 1.58044,\t[Distance] : 0.00591\n",
      "[total] : 3.19068,\t[CrossEntropy] : 1.57846,\t[Distance] : 0.00322\n",
      "[total] : 3.91504,\t[CrossEntropy] : 1.57644,\t[Distance] : 0.00468\n",
      "[total] : 3.52021,\t[CrossEntropy] : 1.57452,\t[Distance] : 0.00389\n",
      "[total] : 3.37809,\t[CrossEntropy] : 1.57263,\t[Distance] : 0.00361\n",
      "[total] : 3.45421,\t[CrossEntropy] : 1.57078,\t[Distance] : 0.00377\n",
      "[total] : 4.54776,\t[CrossEntropy] : 1.56888,\t[Distance] : 0.00596\n",
      "[total] : 2.47290,\t[CrossEntropy] : 1.56716,\t[Distance] : 0.00181\n",
      "[total] : 2.95917,\t[CrossEntropy] : 1.56545,\t[Distance] : 0.00279\n"
     ]
    }
   ],
   "source": [
    "model = CuteModel()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "BETA = 500\n",
    "\n",
    "for e in range(EPOCH):\n",
    "    pp = torch.randint(1,16,[1])\n",
    "    X_original = SAMPLE_X[:,:,:16]        # here only used the half of the input\n",
    "    X_perturbed = SAMPLE_X[:,:,pp:pp+16]  # perturbation : shifting\n",
    "    \n",
    "    p_original = model(X_original)\n",
    "    p_perturbed = model(X_perturbed)\n",
    "    \n",
    "    class_loss = nn.CrossEntropyLoss()(p_original[MASK], SAMPLE_Y[MASK])\n",
    "    dist_loss = nn.MSELoss()(p_original[~MASK], p_perturbed[~MASK])\n",
    "    \n",
    "    loss = class_loss + BETA*dist_loss\n",
    "    print('[total] : %.5f,\\t[CrossEntropy] : %.5f,\\t[Distance] : %.5f'%(loss.item(), class_loss.item(), dist_loss.item()))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
