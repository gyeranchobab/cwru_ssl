{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample of Semi-supervised Learning Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Toy Sample X,Y, MASK\n",
    "SAMPLE_X = torch.rand(8, 1, 32)\n",
    "SAMPLE_Y = torch.randint(2, [8])\n",
    "EPOCH = 20\n",
    "MASK = torch.tensor([True, True, False, False, False, False, False, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CuteModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CuteModel, self).__init__()\n",
    "        \n",
    "        ## encoder layers : Sequence of Convolution Blocks(Conv1d + ReLU + Dropout)\n",
    "        self.enc_layer1 = nn.Conv1d(1, 8, kernel_size=5, stride=2)\n",
    "        self.enc_layer2 = nn.Conv1d(8, 8, kernel_size=5, stride=2)\n",
    "        \n",
    "        ## classifier layers : Multi-Layer Perceptron(FC + ReLU)\n",
    "        self.decoder = nn.Linear(8, 6)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.enc_layer1(x)\n",
    "        x = self.enc_layer2(x)\n",
    "        \n",
    "        x = x.mean(dim=-1)\n",
    "        \n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Pseudo-Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([False, False, False, False, False, False, False, False])\n",
      "tensor([False, False, False, False, False, False, False, False])\n",
      "tensor([False, False, False, False, False, False, False, False])\n",
      "tensor([False, False, False, False, False, False, False, False])\n",
      "tensor([False, False, False, False, False, False, False, False])\n",
      "tensor([False, False, False, False, False, False, False, False])\n",
      "tensor([False, False, False, False, False, False, False, False])\n",
      "tensor([False, False, False, False, False, False, False, False])\n",
      "tensor([False, False, False, False, False, False, False, False])\n",
      "tensor([False, False, False, False, False, False, False, False])\n",
      "tensor([False, False, False, False, False,  True, False, False])\n",
      "tensor([False, False, False, False, False,  True, False, False])\n",
      "tensor([False, False, False, False, False,  True, False, False])\n",
      "tensor([False, False, False,  True,  True,  True, False,  True])\n",
      "tensor([False, False, False,  True,  True,  True,  True,  True])\n",
      "tensor([False, False, False,  True,  True,  True,  True,  True])\n",
      "tensor([False, False, False,  True,  True,  True,  True,  True])\n",
      "tensor([False, False, False,  True,  True,  True,  True,  True])\n",
      "tensor([False, False, False,  True,  True,  True,  True,  True])\n",
      "tensor([False, False, False,  True,  True,  True,  True,  True])\n"
     ]
    }
   ],
   "source": [
    "model = CuteModel()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "THRES = 0.25  # this is very low value for tutorial. You should use higher value(0.7~)\n",
    "\n",
    "for e in range(EPOCH):\n",
    "    p = model(SAMPLE_X)\n",
    "    pred = torch.argmax(p, dim=1)\n",
    "    \n",
    "    prob = F.softmax(p, dim=-1)\n",
    "    PSEUDO = (~MASK) & (prob.max(dim=-1)[0]>THRES)\n",
    "    print(PSEUDO)\n",
    "    p_pseudo = torch.cat([p[MASK], p[PSEUDO]], dim=0)\n",
    "    y_pseudo = torch.cat([SAMPLE_Y[MASK], pred[PSEUDO]], dim=0)\n",
    "    \n",
    "    if PSEUDO.any() or MASK.any():\n",
    "        loss = nn.CrossEntropyLoss()(p_pseudo, y_pseudo)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Entropy Minimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HLoss(x):\n",
    "    b = F.softmax(x, dim=1) * F.log_softmax(x, dim=1)\n",
    "    b = -1.0 * b.mean()\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[total] : 4.63124,\t[CrossEntropy] : 1.71361,\t[Entropy] : 0.29176\n",
      "[total] : 4.60727,\t[CrossEntropy] : 1.69075,\t[Entropy] : 0.29165\n",
      "[total] : 4.58295,\t[CrossEntropy] : 1.66833,\t[Entropy] : 0.29146\n",
      "[total] : 4.55827,\t[CrossEntropy] : 1.64634,\t[Entropy] : 0.29119\n",
      "[total] : 4.53322,\t[CrossEntropy] : 1.62474,\t[Entropy] : 0.29085\n",
      "[total] : 4.50779,\t[CrossEntropy] : 1.60352,\t[Entropy] : 0.29043\n",
      "[total] : 4.48198,\t[CrossEntropy] : 1.58265,\t[Entropy] : 0.28993\n",
      "[total] : 4.45577,\t[CrossEntropy] : 1.56214,\t[Entropy] : 0.28936\n",
      "[total] : 4.42915,\t[CrossEntropy] : 1.54196,\t[Entropy] : 0.28872\n",
      "[total] : 4.40211,\t[CrossEntropy] : 1.52211,\t[Entropy] : 0.28800\n",
      "[total] : 4.37464,\t[CrossEntropy] : 1.50257,\t[Entropy] : 0.28721\n",
      "[total] : 4.34672,\t[CrossEntropy] : 1.48332,\t[Entropy] : 0.28634\n",
      "[total] : 4.31832,\t[CrossEntropy] : 1.46437,\t[Entropy] : 0.28540\n",
      "[total] : 4.28941,\t[CrossEntropy] : 1.44568,\t[Entropy] : 0.28437\n",
      "[total] : 4.25997,\t[CrossEntropy] : 1.42725,\t[Entropy] : 0.28327\n",
      "[total] : 4.22996,\t[CrossEntropy] : 1.40905,\t[Entropy] : 0.28209\n",
      "[total] : 4.19933,\t[CrossEntropy] : 1.39109,\t[Entropy] : 0.28082\n",
      "[total] : 4.16805,\t[CrossEntropy] : 1.37334,\t[Entropy] : 0.27947\n",
      "[total] : 4.13608,\t[CrossEntropy] : 1.35579,\t[Entropy] : 0.27803\n",
      "[total] : 4.10335,\t[CrossEntropy] : 1.33844,\t[Entropy] : 0.27649\n"
     ]
    }
   ],
   "source": [
    "model = CuteModel()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "BETA = 10\n",
    "\n",
    "for e in range(EPOCH):\n",
    "    p = model(SAMPLE_X)\n",
    "    pred = torch.argmax(p, dim=1)\n",
    "    \n",
    "    class_loss = nn.CrossEntropyLoss()(p[MASK], SAMPLE_Y[MASK])\n",
    "    entropy_loss = HLoss(p[~MASK])\n",
    "    \n",
    "    loss = class_loss + BETA*entropy_loss\n",
    "    print('[total] : %.5f,\\t[CrossEntropy] : %.5f,\\t[Entropy] : %.5f'%(loss.item(), class_loss.item(), entropy_loss.item()))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Consistency Regularization\n",
    "you can give perturbation by temporal shift, adding noise, adversarial training, etc.\n",
    "It is important that the perturbation should be realistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CrossEntropy(p,q):\n",
    "    b = F.softmax(p, dim=1) * F.log_softmax(q, dim=1)\n",
    "    b = -1.0*b.mean()\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[total] : 150.16623,\t[CrossEntropy] : 1.99081,\t[Distance] : 0.29635\n",
      "[total] : 150.00821,\t[CrossEntropy] : 2.00101,\t[Distance] : 0.29601\n",
      "[total] : 149.83548,\t[CrossEntropy] : 2.01158,\t[Distance] : 0.29565\n",
      "[total] : 149.64714,\t[CrossEntropy] : 2.02257,\t[Distance] : 0.29525\n",
      "[total] : 149.44200,\t[CrossEntropy] : 2.03406,\t[Distance] : 0.29482\n",
      "[total] : 149.21877,\t[CrossEntropy] : 2.04609,\t[Distance] : 0.29435\n",
      "[total] : 148.97586,\t[CrossEntropy] : 2.05873,\t[Distance] : 0.29383\n",
      "[total] : 148.71144,\t[CrossEntropy] : 2.07203,\t[Distance] : 0.29328\n",
      "[total] : 148.42358,\t[CrossEntropy] : 2.08601,\t[Distance] : 0.29268\n",
      "[total] : 148.11018,\t[CrossEntropy] : 2.10070,\t[Distance] : 0.29202\n",
      "[total] : 147.76906,\t[CrossEntropy] : 2.11615,\t[Distance] : 0.29131\n",
      "[total] : 147.39766,\t[CrossEntropy] : 2.13239,\t[Distance] : 0.29053\n",
      "[total] : 146.99324,\t[CrossEntropy] : 2.14947,\t[Distance] : 0.28969\n",
      "[total] : 146.55266,\t[CrossEntropy] : 2.16741,\t[Distance] : 0.28877\n",
      "[total] : 146.07246,\t[CrossEntropy] : 2.18627,\t[Distance] : 0.28777\n",
      "[total] : 145.54887,\t[CrossEntropy] : 2.20611,\t[Distance] : 0.28669\n",
      "[total] : 144.97771,\t[CrossEntropy] : 2.22701,\t[Distance] : 0.28550\n",
      "[total] : 144.35466,\t[CrossEntropy] : 2.24908,\t[Distance] : 0.28421\n",
      "[total] : 143.67503,\t[CrossEntropy] : 2.27242,\t[Distance] : 0.28281\n",
      "[total] : 142.93390,\t[CrossEntropy] : 2.29714,\t[Distance] : 0.28127\n"
     ]
    }
   ],
   "source": [
    "model = CuteModel()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "BETA = 500\n",
    "\n",
    "for e in range(EPOCH):\n",
    "    X_original = SAMPLE_X[:,:,:-1]  # here only used the half of the input\n",
    "    X_perturbed = SAMPLE_X[:,:,1:]  # perturbation : shifting\n",
    "    \n",
    "    p_original = model(X_original)\n",
    "    p_perturbed = model(X_perturbed)\n",
    "    \n",
    "    class_loss = nn.CrossEntropyLoss()(p_original[MASK], SAMPLE_Y[MASK])\n",
    "    dist_loss = CrossEntropy(p_original, p_perturbed)\n",
    "    \n",
    "    loss = class_loss + BETA*dist_loss\n",
    "    print('[total] : %.5f,\\t[CrossEntropy] : %.5f,\\t[Distance] : %.5f'%(loss.item(), class_loss.item(), dist_loss.item()))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
